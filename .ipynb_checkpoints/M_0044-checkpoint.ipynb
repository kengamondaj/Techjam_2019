{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dummies(data,feature):\n",
    "    temp = pd.get_dummies(data[feature]).rename(columns=lambda x: feature +'_'+ str(x))\n",
    "    data = pd.concat([data, temp], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def add_Kmean_group(data,feature_list):\n",
    "    for feature in feature_list :\n",
    "        model= KMeans(n_clusters=8,random_state=5)\n",
    "        temp = model.fit_predict(pd.DataFrame(data[feature]))\n",
    "        temp = pd.DataFrame(temp,columns=[feature + '_group'])\n",
    "        data = pd.concat([data, temp], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(A, F):\n",
    "    A , F = np.array(A) ,np.array(F)\n",
    "    return 100 - 100/len(A) * np.sum(np.power(np.abs(F - A),2) \\\n",
    "                                     / np.power(np.minimum(2 * np.abs(A),np.abs(F)) + np.abs(A),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_data = pd.read_csv('./data/cc.csv')\n",
    "data = pd.read_csv('data/demographics.csv')\n",
    "kp_data = pd.read_csv('./data/kplus.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "y_train = pd.DataFrame(np.log1p(train['income']))\n",
    "\n",
    "data['ocp_cd'] = data['ocp_cd'].fillna(0)\n",
    "data['ocp_cd'] = data['ocp_cd'].astype(int)\n",
    "\n",
    "df_cc_data = pd.merge(data,cc_data,on=['cc_no'], how=\"left\")\n",
    "\n",
    "df_cc_data_mean = df_cc_data.groupby(['id','gender', 'ocp_cd', 'age'])['cc_txn_amt'].mean()\n",
    "df_cc_data_std = df_cc_data.groupby(['id','gender', 'ocp_cd', 'age'])['cc_txn_amt'].std()\n",
    "df_cc_data_max = df_cc_data.groupby(['id','gender', 'ocp_cd', 'age'])['cc_txn_amt'].max()\n",
    "df_cc_data_min = df_cc_data.groupby(['id','gender', 'ocp_cd', 'age'])['cc_txn_amt'].min()\n",
    "df_cc_data_median = df_cc_data.groupby(['id','gender', 'ocp_cd', 'age'])['cc_txn_amt'].median()\n",
    "df_cc_data_count = df_cc_data.groupby(['id','gender', 'ocp_cd', 'age'])['cc_txn_amt'].count()\n",
    "df_cc_data_sum = df_cc_data.groupby(['id','gender', 'ocp_cd', 'age'])['cc_txn_amt'].sum()\n",
    "\n",
    "df_cc_data = pd.concat([df_cc_data_mean, df_cc_data_std, df_cc_data_max, df_cc_data_min, df_cc_data_median, df_cc_data_count, df_cc_data_sum], axis=1, join='inner')\n",
    "df_cc_data.columns = ['cc_data_mean','cc_data_std', 'cc_data_max', 'cc_data_min', 'cc_data_median', 'cc_data_count', 'cc_data_sum']\n",
    "df_cc_data = df_cc_data.fillna(0)\n",
    "df_cc_data = df_cc_data.reset_index()\n",
    "\n",
    "df_kp_data_mean = kp_data.groupby(['id'])['kp_txn_amt'].mean()\n",
    "df_kp_data_std = kp_data.groupby(['id'])['kp_txn_amt'].std()\n",
    "df_kp_data_max = kp_data.groupby(['id'])['kp_txn_amt'].max()\n",
    "df_kp_data_min = kp_data.groupby(['id'])['kp_txn_amt'].min()\n",
    "df_kp_data_median = kp_data.groupby(['id'])['kp_txn_amt'].median()\n",
    "df_kp_data_count = kp_data.groupby(['id'])['kp_txn_amt'].count()\n",
    "df_kp_data_sum = kp_data.groupby(['id'])['kp_txn_amt'].sum()\n",
    "\n",
    "df_kp_data = pd.concat([df_kp_data_mean, df_kp_data_std, df_kp_data_max, df_kp_data_min, df_kp_data_median, df_kp_data_count, df_kp_data_sum], axis=1, join='inner')\n",
    "df_kp_data.columns = ['kp_data_mean', 'kp_data_std', 'kp_data_max', 'kp_data_min', 'kp_data_median', 'kp_data_count', 'kp_data_sum']\n",
    "df_kp_data = df_kp_data.fillna(0)\n",
    "df_kp_data = df_kp_data.reset_index()\n",
    "\n",
    "sum_all_data = pd.merge(df_cc_data,df_kp_data,on=['id'], how=\"left\")\n",
    "sum_all_data = sum_all_data.fillna(0)\n",
    "\n",
    "sum_all_data['sum_amt'] = sum_all_data['kp_data_sum'] + sum_all_data['cc_data_sum']\n",
    "\n",
    "feature_list = ['sum_amt','cc_data_mean', 'cc_data_std',\n",
    "       'cc_data_max', 'cc_data_min', 'cc_data_median', 'cc_data_count',\n",
    "       'cc_data_sum', 'kp_data_mean', 'kp_data_std', 'kp_data_max',\n",
    "       'kp_data_min', 'kp_data_median', 'kp_data_count', 'kp_data_sum']\n",
    "sum_all_data = add_Kmean_group(sum_all_data,feature_list)\n",
    "\n",
    "feature_list = ['gender', 'ocp_cd', 'age','sum_amt_group', 'cc_data_mean_group', 'cc_data_std_group',\n",
    "       'cc_data_max_group', 'cc_data_min_group', 'cc_data_median_group',\n",
    "       'cc_data_count_group', 'cc_data_sum_group', 'kp_data_mean_group',\n",
    "       'kp_data_std_group', 'kp_data_max_group', 'kp_data_min_group',\n",
    "       'kp_data_median_group', 'kp_data_count_group', 'kp_data_sum_group']\n",
    "for feature in feature_list :\n",
    "    sum_all_data = make_dummies(sum_all_data,feature)\n",
    "\n",
    "sum_all_data = sum_all_data.drop(columns=['id'])\n",
    "x_train,x_test = sum_all_data.head(50000),sum_all_data.tail(15000)\n",
    "\n",
    "x_train.to_csv('x_train.csv',index=False)    \n",
    "x_test.to_csv('x_test.csv',index=False)\n",
    "y_train.to_csv('y_train_log.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kengamd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('x_train.csv')    \n",
    "y_train = pd.read_csv('y_train_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START ML 2019-11-11 13:24:09.666291\n",
      "START Fit\n",
      "stack_gen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kengamd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:55:19] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:55:24] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:55:28] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:55:32] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:55:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:55:42] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:01:22] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "xgboost\n",
      "[14:01:28] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stack_model.sav']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('START ML', datetime.now(), )\n",
    "\n",
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# setup models    \n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "ridge = make_pipeline(RobustScaler(),\n",
    "                      RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(),\n",
    "                      LassoCV(max_iter=1e7, alphas=alphas2,\n",
    "                              random_state=42, cv=kfolds))\n",
    "\n",
    "elasticnet = make_pipeline(RobustScaler(),\n",
    "                           ElasticNetCV(max_iter=1e7, alphas=e_alphas,\n",
    "                                        cv=kfolds, l1_ratio=e_l1ratio,random_state=42))\n",
    "                                        \n",
    "svr = make_pipeline(RobustScaler(),\n",
    "                      SVR(C= 20, epsilon= 0.008, gamma=0.0003))\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =42)\n",
    "\n",
    "xgboost = XGBRegressor(learning_rate=0.1, n_estimators=40,\n",
    "                                     max_depth=6, min_child_weight=0,\n",
    "                                     gamma=0.8, subsample=0.5,\n",
    "                                     colsample_bytree=0.5,colsample_bylevel=1,nthread=4,random_state=42)\n",
    "\n",
    "# stack\n",
    "stack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet,\n",
    "                                            gbr, xgboost),\n",
    "                                meta_regressor=xgboost,\n",
    "                                use_features_in_secondary=True,random_state=42)\n",
    "\n",
    "print('START Fit')\n",
    "\n",
    "print('stack_gen')\n",
    "stack_model = stack_gen.fit(np.array(x_train), np.array(y_train))\n",
    "\n",
    "print('xgboost')\n",
    "xgb_model = xgboost.fit(x_train, y_train)\n",
    "\n",
    "filename = 'xgb_model.sav'\n",
    "joblib.dump(xgb_model, filename)\n",
    "\n",
    "filename = 'stack_model.sav'\n",
    "joblib.dump(stack_model, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_models_predict(X):\n",
    "    return ((0.5* pd.DataFrame(np.expm1(xgb_model.predict(X)))) + \\\n",
    "            (0.5* pd.DataFrame(np.expm1(stack_model.predict(np.array(X))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:06:59] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:07:00] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:07:00] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:07:00] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "x_test = pd.read_csv('x_test.csv')\n",
    "xgb_model = joblib.load('xgb_model.sav')\n",
    "stack_model = joblib.load('stack_model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = blend_models_predict(x_test)\n",
    "ans = pd.read_csv('data/test.csv')\n",
    "ans['income'] = pred\n",
    "ans['income'] = ans['income']+1000\n",
    "ans.to_csv('O_0044.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33025.16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans['income'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
